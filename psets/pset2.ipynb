{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b601bd-43e8-4d3e-b733-c8a3e6d58fe1",
   "metadata": {},
   "source": [
    "# 18.S097/16.S092 Problem Set 2\n",
    "\n",
    "Due Friday 4/18 at **11:59pm**; 20% penalty if it is turned in within 24 hours, and after that late psets will not be accepted without prior arrangement.   Submit in PDF format: a decent-quality scan/image of any handwritten solutions (e.g. get a scanner app on your phone or use a tablet), combined with a PDF printout of your Jupyter notebook showing your code and (clearly labeled) results.\n",
    "\n",
    "**TO GENERATE A PDF OF YOUR JUPYTER NOTEBOOK:** In the Jupyter client (e.g. the [JupyterLab Desktop](https://github.com/jupyterlab/jupyterlab-desktop) app), in the *File* pull-down menu, select *Save and Export Notebook As*, and then select the *HTML* format (not PDF, which may require special software).  Then open the downloaded HTML file with your favorite browser, and use the browser's *Print* function to generate the PDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1dbef1",
   "metadata": {},
   "source": [
    "## Problem 1 (5+5+5 points)\n",
    "\n",
    "**(a)** Implement the power method for the $5 \\times 5$ matrix $A=A^T$ with entries given below (in Julia format, but you can easily paste the rows into Python if you want), starting with a random $x$.  (Don't forget to normalize $x$ on each step.)  Plot the first component `x[1]` of the vector (`x[0]` in Python) as a function of the iteration $k$, for 50 iterations.    You should find that it is *not* converging, even if you do thousands of iterations.  Explain why, by analyzing $A$.\n",
    "\n",
    "**(b)** For the same power iteration, also plot the estimated eigenvalue from the Rayleigh quotient $R(x) = x^T A x / x^T x$.   Show experimentally that this ratio *is* converging with iteration, but that it converges to a *different* value depending on the starting $x$.   Explain this theoretically.  (Hint: imagine expanding your initial vector in terms of the eigenvectors of $A$, and write $R(x)$ as we did in class.  What happens as the iterations increase?  Your analysis of $A$ from part (a) is relevant here.)\n",
    "\n",
    "**(c)** Take the **last two iterations** $x_{49}, x_{50}$ of your power iteration from part (a).   Given these two vectors, construct an orthonormal basis for their span and implement the Rayleigh–Ritz procedure from class.  Show that the Ritz values accurately give you the biggest two $|\\lambda|$ of $A$ and that the Ritz vectors are corresponding eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e89401-be6a-43bc-9cce-c3b5b36f2179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Matrix{Float64}:\n",
       "  1.44763   -0.646539    0.203394     -0.601088   0.233071\n",
       " -0.646539   0.245131   -0.0109106    -0.224521   1.10267\n",
       "  0.203394  -0.0109106   0.552757      1.23921   -0.000396612\n",
       " -0.601088  -0.224521    1.23921      -0.289257   0.894155\n",
       "  0.233071   1.10267    -0.000396612   0.894155   0.043737"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [1.4476317999449781 -0.6465393230357954   0.2033943818754874    -0.6010878430154134  0.23307116396384292\n",
    "    -0.6465393230357954  0.245131330148544   -0.010910634569569148  -0.22452148400766606 1.102670053450075\n",
    "     0.2033943818754874 -0.010910634569569148 0.5527569734349188     1.2392098548325268 -0.00039661249386200957\n",
    "    -0.6010878430154134 -0.22452148400766606  1.2392098548325268    -0.2892571481659739  0.8941545793109221\n",
    "     0.23307116396384292 1.102670053450075   -0.00039661249386200957 0.8941545793109221  0.043737044637532294]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ac28da",
   "metadata": {},
   "source": [
    "## Problem 2 (5+5 points)\n",
    "\n",
    "Consider the Rayleigh quotient $R(x) = \\frac{x^T A x}{x^T x}$ for a real matrix $A$.\n",
    "\n",
    "**(a)** Suppose $A = A^T$.  In class, we claimed that *any* eigenvector of $A$ will then be an extremum of $R$.  Show this: explicitly compute $\\nabla R$ (exercise your 18.02 skills!) and show that $\\nabla R = 0$ if and only if $x$ is an eigenvector.\n",
    "\n",
    "**(b)** Suppose that $A \\ne A^T$.   In this case, eigenvectors of $A$ will *not* generally be extrema of $R$.  Instead, the extrema of $R$ (where $\\nabla R = 0$) will be eigenvectors of *some other* matrix.  What matrix?  (Revisit your calculation from (a): what changes if $A$ is not symmetric?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73089a",
   "metadata": {},
   "source": [
    "## Problem 3 (5+5+5 points)\n",
    "\n",
    "This problem is based problem 8.3.5 from the [*FNC* book section 8.3](https://fncbook.com/inviter).  This exercise concerns the $n^2\\times n^2$ sparse matrix defined by `A = FNC.poisson(n)` for integer $n$ — see the provided [Julia implementation](https://github.com/fncbook/FNCFunctions.jl/blob/236e736cd052081d67c487c8835dcabb0221437a/src/chapter08.jl#L153-L166) or the [Python implementation `poisson2d(n)`](https://github.com/fncbook/fnc/blob/0149be86ebf930b6455c3b8500f8dc818afadda7/python/pkg/FNC/FNC08.py#L135-L141). It represents a discretized ($n \\times n$ grid) model of a vibrating square membrane held fixed around the edges.\n",
    "\n",
    "**(a)** Implement inverse iteration (the power method with $A^{-1}$) with zero shift).  Do *not* explicitly compute $A^{-1}$.  Instead, compute a sparse LU factorization *once* (or better yet sparse Cholesky, since this matrix is symmetric positive-definite) using an appropriate library function, and re-use it for each power iteration.  Using sufficiently many iterations your code, **find the eigenvalue** $\\lambda$ closest to zero for $n=10,15,20,25$ to many digits of accuracy.\n",
    "\n",
    "The eigenvalues can be interpreted as the squares of the vibration frequencies.  It turns out that the lowest vibration frequency is $\\sqrt{2}$ for an exact wave equation in the $n \\to \\infty$ limit, so the lowest eigenvalue should be converging to $2$ as $n$ increases.  `poisson` uses a second-order center-difference approximation, so the error should be $O(1/n^2)$ — **verify that your λ data** is consistent with this prediction.\n",
    "\n",
    "**(b)** For each $n$ in part (a), apply 50 steps of inverse iteration. On one graph, **plot the convergence of fractional error** $|\\Delta \\lambda| / |\\lambda|$ in the estimated eigenvalue  **as a function of iteration** for each of the four $n$'s.  (Use the value from (a) as the \"exact\" value … if you ran (a) for much more than 50 iterations it should be accurate enough.)  Why should this converge at similar rates for different $n$ values?\n",
    "\n",
    "**(c)** Let `v` be the eigenvector found by your inverse iteration for $n=25$. **Make a plot of the vibration mode** by reshaping `v` into an $n\\times n$ matrix (use something like a heatmap, contour, or 3d surface plot).   For $n \\to \\infty$, it turns out that this eigenvector should converge to the function $\\sin(x) \\sin(y)$ on a $[0,\\pi] \\times [0, \\pi]$ domain — **plot this analytical solution side-by-side** with your computed eigenvector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
